<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="REC," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="一篇非常好的博文  一些假设我们有一个用户-物品评分矩阵：  每个用户可以被k个属性或特征描述 每个物品也可以用一组一致的k个属性或特征描述 如果我们将用户的每个特征乘以物品的相应特征并将所有内容加在一起，那么将会得到用户给予物品的评级的近似值矩阵。  不用知道特征和属性具体是什么，也不用知道k的值为多少。我们只需要选一个k值，然后进行学习即可。  怎么学习？最小化损失函数！">
<meta name="keywords" content="REC">
<meta property="og:type" content="article">
<meta property="og:title" content="Explicit Matrix Factorization with ALS and SGD">
<meta property="og:url" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/index.html">
<meta property="og:site_name" content="Think Island">
<meta property="og:description" content="一篇非常好的博文  一些假设我们有一个用户-物品评分矩阵：  每个用户可以被k个属性或特征描述 每个物品也可以用一组一致的k个属性或特征描述 如果我们将用户的每个特征乘以物品的相应特征并将所有内容加在一起，那么将会得到用户给予物品的评级的近似值矩阵。  不用知道特征和属性具体是什么，也不用知道k的值为多少。我们只需要选一个k值，然后进行学习即可。  怎么学习？最小化损失函数！">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_6_0.png">
<meta property="og:image" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_7_0.png">
<meta property="og:image" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_9_0.png">
<meta property="og:image" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_13_0.png">
<meta property="og:image" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_17_0.png">
<meta property="og:updated_time" content="2018-03-29T02:15:13.139Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Explicit Matrix Factorization with ALS and SGD">
<meta name="twitter:description" content="一篇非常好的博文  一些假设我们有一个用户-物品评分矩阵：  每个用户可以被k个属性或特征描述 每个物品也可以用一组一致的k个属性或特征描述 如果我们将用户的每个特征乘以物品的相应特征并将所有内容加在一起，那么将会得到用户给予物品的评级的近似值矩阵。  不用知道特征和属性具体是什么，也不用知道k的值为多少。我们只需要选一个k值，然后进行学习即可。  怎么学习？最小化损失函数！">
<meta name="twitter:image" content="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_6_0.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/"/>





  <title>Explicit Matrix Factorization with ALS and SGD | Think Island</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Think Island</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="lhy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/me.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think Island">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Explicit Matrix Factorization with ALS and SGD</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-29T09:26:44+08:00">
                2018-03-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>一篇非常好的<a href="http://blog.ethanrosenthal.com/2016/01/09/explicit-matrix-factorization-sgd-als/" target="_blank" rel="noopener">博文</a></p>
</blockquote>
<h3 id="一些假设"><a href="#一些假设" class="headerlink" title="一些假设"></a>一些假设</h3><p>我们有一个用户-物品评分矩阵：</p>
<ul>
<li>每个用户可以被k个属性或特征描述</li>
<li>每个物品也可以用一组一致的k个属性或特征描述</li>
<li>如果我们将用户的每个特征乘以物品的相应特征并将所有内容加在一起，那么将会得到用户给予物品的评级的近似值矩阵。</li>
</ul>
<p>不用知道特征和属性具体是什么，也不用知道k的值为多少。我们只需要选一个k值，然后进行学习即可。</p>
<p><strong> 怎么学习？最小化损失函数！ </strong></p>
<a id="more"></a>
<h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><p>用户u对物品i的评分估计为：</p>
<script type="math/tex; mode=display">\hat r_{ui} = \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i} = \sum\limits_{k} x_{uk}y_{ki}</script><p>带正则项的MSE损失函数为：</p>
<script type="math/tex; mode=display">L = \sum\limits_{u,i \in S}(r_{ui} - \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i})^{2} + \lambda_{x} \sum\limits_{u} \left\Vert \textbf{x}_{u} \right\Vert^{2} + \lambda_{y} \sum\limits_{u} \left\Vert \textbf{y}_{i} \right\Vert^{2}</script><h3 id="最小化损失函数"><a href="#最小化损失函数" class="headerlink" title="最小化损失函数"></a>最小化损失函数</h3><h4 id="ALS（交替最小二乘法）"><a href="#ALS（交替最小二乘法）" class="headerlink" title="ALS（交替最小二乘法）"></a>ALS（交替最小二乘法）</h4><p><em>交替选取待优化向量，将其他向量设为已知，求得当前向量最优值（令导数为0）后，再选取优化另一个向量。重复这个过程，直至收敛。</em></p>
<h5 id="求导"><a href="#求导" class="headerlink" title="求导"></a>求导</h5><ol>
<li>我们将物品向量$y_i$固定，优化用户向量$x_u$。$L$对$x_u$求一阶导数：<script type="math/tex; mode=display">\frac{\partial L}{\partial \textbf{x}_{u}} = - 2 \sum\limits_{i}(r_{ui} - \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i}) \textbf{y}_{i}^{\intercal} + 2 \lambda_{x} \textbf{x}_{u}^{\intercal}</script></li>
<li><p>令导数为0，优化$x_u$。（对于向量乘积的和变为矩阵的规则，可以参考这个<a href="https://math.stackexchange.com/questions/2587419/changing-sum-of-vector-products-to-a-matrix?noredirect=1" target="_blank" rel="noopener">回答</a>)</p>
<script type="math/tex; mode=display">0 = -(\textbf{r}_{u} - \textbf{x}_{u}^{\intercal} Y^{\intercal})Y + \lambda_{x} \textbf{x}_{u}^{\intercal}</script><script type="math/tex; mode=display">\textbf{x}_{u}^{\intercal}(Y^{\intercal}Y + \lambda_{x}I) = \textbf{r}_{u}Y</script><script type="math/tex; mode=display">\textbf{x}_{u}^{\intercal} = \textbf{r}_{u}Y(Y^{\intercal}Y + \lambda_{x}I)^{-1}</script><p> 对$x_{uk}$有：</p>
<script type="math/tex; mode=display">x_{uk} = r_{ui}Y_{ik}(Y_{ki}Y_{ik} + \lambda_{x}I_{kk})^{-1}</script></li>
<li><p>将用户向量$x_u$固定，优化物品向量$y_i$。</p>
<script type="math/tex; mode=display">\frac{\partial L}{\partial \textbf{y}_{i}} = - 2 \sum\limits_{i}(r_{iu} - \textbf{y}_{i}^{\intercal} \cdot{} \textbf{x}_{u}) \textbf{x}_{u}^{\intercal} + 2 \lambda_{y} \textbf{y}_{i}^{\intercal}</script><script type="math/tex; mode=display">0 = -(\textbf{r}_{i} - \textbf{y}_{i}^{\intercal} X^{\intercal})X + \lambda_{y} \textbf{y}_{i}^{\intercal}</script><script type="math/tex; mode=display">\textbf{y}_{i}^{\intercal} ( X^{\intercal}X +  \lambda_{y}I) =  \textbf{r}_{i} X</script><script type="math/tex; mode=display">\textbf{y}_{i}^{\intercal} =  \textbf{r}_{i} X  ( X^{\intercal}X +  \lambda_{y}I) ^{-1}</script></li>
<li>重复以上过程直至收敛。</li>
</ol>
<h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#之前处理数据集的步骤</span></span><br><span class="line"><span class="comment">#读取文件</span></span><br><span class="line">names = [<span class="string">'user_id'</span>, <span class="string">'item_id'</span>, <span class="string">'rating'</span>, <span class="string">'timestamp'</span>]</span><br><span class="line">df = pd.read_csv(<span class="string">'./ml-100k/u.data'</span>, sep=<span class="string">'\t'</span>, names=names)</span><br><span class="line"><span class="comment">#获取user和item数量</span></span><br><span class="line">n_users = df.user_id.unique().shape[<span class="number">0</span>]</span><br><span class="line">n_items = df.item_id.unique().shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#生成评分表</span></span><br><span class="line">ratings = np.zeros((n_users,n_items))</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.itertuples():  <span class="comment">#返回一行元素，row[0]为行的idx</span></span><br><span class="line">    ratings[row[<span class="number">1</span>]<span class="number">-1</span>,row[<span class="number">2</span>]<span class="number">-1</span>] = row[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#分割训练集与测试集 从每个用户的评分中移出10个给测试集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_test_split</span><span class="params">(ratings)</span>:</span></span><br><span class="line">    test = np.zeros(ratings.shape)</span><br><span class="line">    train = ratings.copy()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> range(ratings.shape[<span class="number">0</span>]):</span><br><span class="line">        test_ratings = np.random.choice(ratings[user, :].nonzero()[<span class="number">0</span>], size=<span class="number">10</span>, replace=<span class="keyword">False</span>) <span class="comment">#从不为0的idx中选出10个，且不重复</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#分别赋值</span></span><br><span class="line">        train[user,test_ratings] = <span class="number">0.</span></span><br><span class="line">        test[user, test_ratings] = ratings[user, test_ratings]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 测试是否完全正交</span></span><br><span class="line">    <span class="keyword">assert</span>(np.all((train * test) == <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train, test</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算MSE</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mse</span><span class="params">(pred, test)</span>:</span></span><br><span class="line">    <span class="comment">#忽略test中为0的项</span></span><br><span class="line">    pred = pred[test.nonzero()].flatten()</span><br><span class="line">    test = test[test.nonzero()].flatten()</span><br><span class="line">    <span class="keyword">return</span> mean_squared_error(pred, test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train, test = train_test_split(ratings)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> solve <span class="comment">#求解线性方程ax=b的函数 input a,b;return x</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#训练预测显式反馈MF的类（ALS方法）</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExplicitMF</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""用ALS方法训练一个矩阵分解模型，用以预测矩阵中空缺的项目"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ratings, n_factors=<span class="number">40</span>, item_reg=<span class="number">0.0</span>, user_reg=<span class="number">0.0</span>, verbose=False)</span>:</span></span><br><span class="line">        <span class="string">"""初始化</span></span><br><span class="line"><span class="string">        Params：</span></span><br><span class="line"><span class="string">        ratings : (ndarray) 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">        n_factors : (int) 矩阵分解模型中隐含特征的个数</span></span><br><span class="line"><span class="string">        item_reg : (float) 物品隐变量正则化系数</span></span><br><span class="line"><span class="string">        user_reg : (float) 用户隐变量正则化系数</span></span><br><span class="line"><span class="string">        verbose : (bool) 是否输出训练进度信息</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.ratings = ratings</span><br><span class="line">        self.n_users, self.n_items = ratings.shape</span><br><span class="line">        self.n_factors = n_factors</span><br><span class="line">        self.item_reg = item_reg</span><br><span class="line">        self.user_reg = user_reg</span><br><span class="line">        self._v = verbose</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als_step</span><span class="params">(self, latent_vectors, fixed_vecs, ratings, _lambda, type=<span class="string">'user'</span>)</span>:</span></span><br><span class="line">        <span class="string">"""ALS算法中的一步//type决定优化的是用户隐变量还是物品隐变量"""</span></span><br><span class="line">        <span class="keyword">if</span> type == <span class="string">'user'</span>:</span><br><span class="line">            YTY = fixed_vecs.T.dot(fixed_vecs)</span><br><span class="line">            lambdaI = np.eye(YTY.shape[<span class="number">0</span>]) * _lambda <span class="comment">#np.eye(n)返回一个n*n的单位对角矩阵</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> u <span class="keyword">in</span> range(latent_vectors.shape[<span class="number">0</span>]):</span><br><span class="line">                latent_vectors[u,:] = solve((YTY+lambdaI), ratings[u,:].dot(fixed_vecs)) <span class="comment">#解线性方程</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> type == <span class="string">'item'</span>:</span><br><span class="line">            XTX = fixed_vecs.T.dot(fixed_vecs)</span><br><span class="line">            lambdaI = np.eye(XTX.shape[<span class="number">0</span>]) * _lambda</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(ratings.shape[<span class="number">1</span>]):</span><br><span class="line">                latent_vectors[i,:] = solve((XTX+lambdaI), ratings[:, i].T.dot(fixed_vecs))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> latent_vectors</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial_train</span><span class="params">(self, n_iter)</span>:</span></span><br><span class="line">        <span class="string">"""部分训练，可多次调用"""</span></span><br><span class="line">        ctr = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> ctr &lt;= n_iter:</span><br><span class="line">            <span class="keyword">if</span> ctr%<span class="number">10</span> == <span class="number">0</span> <span class="keyword">and</span> self._v:</span><br><span class="line">                print(<span class="string">"current iteration &#123;&#125;\n"</span>.format(ctr))</span><br><span class="line">            self.user_vects = self.als_step(self.user_vects, self.item_vects, self.ratings, self.user_reg, type=<span class="string">'user'</span>)</span><br><span class="line">            self.item_vects = self.als_step(self.item_vects, self.user_vects, self.ratings, self.item_reg, type=<span class="string">'item'</span>)</span><br><span class="line">            ctr += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, n_iter)</span>:</span></span><br><span class="line">        <span class="comment">#初始化用户和物品隐变量</span></span><br><span class="line">        self.user_vects = np.random.random((self.n_users, self.n_factors))</span><br><span class="line">        self.item_vects = np.random.random((self.n_items, self.n_factors))</span><br><span class="line">        </span><br><span class="line">        self.partial_train(n_iter)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, u, i)</span>:</span></span><br><span class="line">        <span class="string">"""预测用户u对物品i的评分"""</span></span><br><span class="line">        <span class="keyword">return</span> self.user_vects[u,:].dot(self.item_vects[i,:].T)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""预测整个评分矩阵"""</span></span><br><span class="line">        predictions = np.zeros((self.user_vects.shape[<span class="number">0</span>], self.item_vects.shape[<span class="number">0</span>]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> u <span class="keyword">in</span> range(self.user_vects.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.item_vects.shape[<span class="number">0</span>]):</span><br><span class="line">                predictions[u,i] = self.predict(u,i)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_learning_curve</span><span class="params">(self, iter_array, test)</span>:</span></span><br><span class="line">        <span class="string">"""在训练中实时追踪MSE值"""</span></span><br><span class="line">        iter_array.sort()</span><br><span class="line">        self.train_mse = []</span><br><span class="line">        self.test_mse = []</span><br><span class="line">        iter_diff = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> (i, n_iter) <span class="keyword">in</span> enumerate(iter_array):</span><br><span class="line">            <span class="keyword">if</span> self._v:</span><br><span class="line">                print(<span class="string">"Iteration: &#123;&#125;"</span>.format(n_iter))</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                self.train(n_iter - iter_diff)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.partial_train(n_iter - iter_diff)</span><br><span class="line">            </span><br><span class="line">            predictions = self.predict_all()</span><br><span class="line">            </span><br><span class="line">            self.train_mse += [get_mse(predictions, ratings)]</span><br><span class="line">            self.test_mse += [get_mse(predictions, test)]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> self._v:</span><br><span class="line">                print(<span class="string">"train mse: "</span>+ str(self.train_mse[<span class="number">-1</span>]))</span><br><span class="line">                print(<span class="string">"tset mse: "</span>+ str(self.test_mse[<span class="number">-1</span>]))</span><br><span class="line">            iter_diff = n_iter</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个画图函数</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span><span class="params">(iter_array, model)</span>:</span></span><br><span class="line">    plt.plot(iter_array, model.train_mse, \</span><br><span class="line">             label=<span class="string">'Training'</span>, linewidth=<span class="number">5</span>)</span><br><span class="line">    plt.plot(iter_array, model.test_mse, \</span><br><span class="line">             label=<span class="string">'Test'</span>, linewidth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.xticks(fontsize=<span class="number">16</span>);</span><br><span class="line">    plt.yticks(fontsize=<span class="number">16</span>);</span><br><span class="line">    plt.xlabel(<span class="string">'iterations'</span>, fontsize=<span class="number">30</span>);</span><br><span class="line">    plt.ylabel(<span class="string">'MSE'</span>, fontsize=<span class="number">30</span>);</span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>, fontsize=<span class="number">20</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#不用正则项训练一下</span></span><br><span class="line">MF_ALS = ExplicitMF(train, n_factors=<span class="number">40</span>, \</span><br><span class="line">                    user_reg=<span class="number">0.0</span>, item_reg=<span class="number">0.0</span>)</span><br><span class="line">iter_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">MF_ALS.calculate_learning_curve(iter_array, test)</span><br><span class="line">plot_learning_curve(iter_array, MF_ALS)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_6_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用正则项训练一下</span></span><br><span class="line">MF_ALS = ExplicitMF(train, n_factors=<span class="number">40</span>, \</span><br><span class="line">                    user_reg=<span class="number">1.0</span>, item_reg=<span class="number">1.0</span>)</span><br><span class="line">iter_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">MF_ALS.calculate_learning_curve(iter_array, test)</span><br><span class="line">plot_learning_curve(iter_array, MF_ALS)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#不断尝试以获得最优的超参数值</span></span><br><span class="line">latent_factors = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">80</span>]</span><br><span class="line">regularizations = [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.</span>, <span class="number">10.</span>, <span class="number">100.</span>]</span><br><span class="line">regularizations.sort()</span><br><span class="line">iter_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">best_params = &#123;&#125;</span><br><span class="line">best_params[<span class="string">'n_factors'</span>] = latent_factors[<span class="number">0</span>]</span><br><span class="line">best_params[<span class="string">'reg'</span>] = regularizations[<span class="number">0</span>]</span><br><span class="line">best_params[<span class="string">'n_iter'</span>] = <span class="number">0</span></span><br><span class="line">best_params[<span class="string">'train_mse'</span>] = np.inf <span class="comment">#无穷大</span></span><br><span class="line">best_params[<span class="string">'test_mse'</span>] = np.inf</span><br><span class="line">best_params[<span class="string">'model'</span>] = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fact <span class="keyword">in</span> latent_factors:</span><br><span class="line">    print(<span class="string">"Factors: &#123;&#125;"</span>.format(fact))</span><br><span class="line">    <span class="keyword">for</span> reg <span class="keyword">in</span> regularizations:</span><br><span class="line">        <span class="comment">#不断尝试并在取得更优效果时更新best_params</span></span><br><span class="line">        print(<span class="string">"Regularizaton: &#123;&#125;"</span>.format(reg))</span><br><span class="line">        MF_ALS = ExplicitMF(train, n_factors=fact, item_reg=reg, user_reg=reg)</span><br><span class="line">        MF_ALS.calculate_learning_curve(iter_array, test)</span><br><span class="line">        min_idx = np.argmin(MF_ALS.test_mse) <span class="comment">#此次训练最小值</span></span><br><span class="line">        <span class="keyword">if</span> MF_ALS.test_mse[min_idx] &lt; best_params[<span class="string">'test_mse'</span>]:</span><br><span class="line">            best_params[<span class="string">'n_factors'</span>] = fact</span><br><span class="line">            best_params[<span class="string">'reg'</span>] = reg</span><br><span class="line">            best_params[<span class="string">'n_iter'</span>] = iter_array[min_idx]</span><br><span class="line">            best_params[<span class="string">'train_mse'</span>] = MF_ALS.train_mse[min_idx]</span><br><span class="line">            best_params[<span class="string">'test_mse'</span>] = MF_ALS.test_mse[min_idx]</span><br><span class="line">            best_params[<span class="string">'model'</span>] = MF_ALS</span><br><span class="line">            print(<span class="string">"New optimal hyperparameters"</span>)</span><br><span class="line">            print(pd.Series(best_params)) <span class="comment">#pandas的一维标签数据结构</span></span><br></pre></td></tr></table></figure>
<pre><code>Factors: 5
Regularizaton: 0.01
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65fcf5c0&gt;
n_factors                                                 5
n_iter                                                   25
reg                                                    0.01
test_mse                                             8.6794
train_mse                                           6.37137
dtype: object
Regularizaton: 0.1
Regularizaton: 1.0
Regularizaton: 10.0
Regularizaton: 100.0
Factors: 10
Regularizaton: 0.01
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65fcf6a0&gt;
n_factors                                                10
n_iter                                                  100
reg                                                    0.01
test_mse                                             8.2038
train_mse                                           5.65925
dtype: object
Regularizaton: 0.1
Regularizaton: 1.0
Regularizaton: 10.0
Regularizaton: 100.0
Factors: 20
Regularizaton: 0.01
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65fcf5c0&gt;
n_factors                                                20
n_iter                                                   50
reg                                                    0.01
test_mse                                             8.0696
train_mse                                           5.06753
dtype: object
Regularizaton: 0.1
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65fcf6a0&gt;
n_factors                                                20
n_iter                                                  100
reg                                                     0.1
test_mse                                            8.06893
train_mse                                           5.07316
dtype: object
Regularizaton: 1.0
Regularizaton: 10.0
Regularizaton: 100.0
Factors: 40
Regularizaton: 0.01
Regularizaton: 0.1
Regularizaton: 1.0
Regularizaton: 10.0
Regularizaton: 100.0
Factors: 80
Regularizaton: 0.01
Regularizaton: 0.1
Regularizaton: 1.0
Regularizaton: 10.0
Regularizaton: 100.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画图看看最佳的模型效果</span></span><br><span class="line">best_als_model = best_params[<span class="string">'model'</span>]</span><br><span class="line">plot_learning_curve(iter_array, best_als_model)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_9_0.png" alt="png"></p>
<h4 id="SGD（随机梯度下降）"><a href="#SGD（随机梯度下降）" class="headerlink" title="SGD（随机梯度下降）"></a>SGD（随机梯度下降）</h4><p><em>将每个待优化变量按其梯度下降最快的方向（导数为0）下降，随机指每次选取一个样本，按此样本的值优化 </em></p>
<h5 id="新的评分-损失公式"><a href="#新的评分-损失公式" class="headerlink" title="新的评分/损失公式"></a>新的评分/损失公式</h5><p>考虑偏差值。$\mu$为全局偏差，$b_u$为用户偏差，$b_i$为物品偏差。<br>则新的评分预估为：</p>
<script type="math/tex; mode=display">\hat r_{ui} = \mu + b_{u} + b_{i} + \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i}</script><p>对应的MSE公式更新为：</p>
<script type="math/tex; mode=display">L = \sum\limits_{u,i}(r_{ui} - (\mu + b_{u} + b_{i} + \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i}))^{2} + 
\lambda_{xb} \sum\limits_{u} \left\Vert b_{u} \right\Vert^{2} + \lambda_{yb} \sum\limits_{i} \left\Vert b_{i} \right\Vert^{2} + \lambda_{xf} \sum\limits_{u} \left\Vert \textbf{x}_{u} \right\Vert^{2} + \lambda_{yf} \sum\limits_{u} \left\Vert \textbf{y}_{i} \right\Vert^{2}</script><h5 id="变量更新规则"><a href="#变量更新规则" class="headerlink" title="变量更新规则"></a>变量更新规则</h5><p>以$b_u$为例：（$\eta$为学习率，即控制更新快慢的超参数）</p>
<script type="math/tex; mode=display">b_{u} \leftarrow b_{u} - \eta \frac{\partial L}{\partial b_{u}}</script><p>对$b_u$求导：</p>
<script type="math/tex; mode=display">\frac{\partial L}{\partial b_{u}} = 2(r_{ui}-(\mu + b_{u} + b_{i} + \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i}))(-1) + 2\lambda_{xb} b_{u}</script><p>令$e_{ui}$为预测误差，即$e_{ui} = r_{ui}-(\mu + b_{u} + b_{i} + \textbf{x}_{u}^{\intercal} \cdot{} \textbf{y}_{i})$：</p>
<script type="math/tex; mode=display">\frac{\partial L}{\partial b_{u}} = 2(e_{ui})(-1) + 2\lambda_{xb} b_{u}</script><script type="math/tex; mode=display">\frac{\partial L}{\partial b_{u}} = - e_{ui} + \lambda_{xb} b_{u}</script><p>则更新规则为：</p>
<script type="math/tex; mode=display">b_{u} \leftarrow b_{u} + \eta \, (e_{ui} - \lambda_{xb} b_{u})</script><p>对其余的变量也是如此：</p>
<script type="math/tex; mode=display">b_{i} \leftarrow b_{i} + \eta \, (e_{ui} - \lambda_{yb} b_{i})</script><script type="math/tex; mode=display">\textbf{x}_{u} \leftarrow \textbf{x}_{u} + \eta \, (e_{ui}\textbf{y}_{i} - \lambda_{xf} \textbf{x}_{u})</script><script type="math/tex; mode=display">\textbf{y}_{i} \leftarrow \textbf{y}_{i} + \eta \, (e_{ui}\textbf{x}_{u} - \lambda_{yf} \textbf{y}_{i})</script><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><p>更改上面的ExplicitMF类，使之既可以使用als方法，又可以使用sgd方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExplicitMF</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""用ALS/SGD方法训练一个矩阵分解模型，用以预测矩阵中空缺的项目"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ratings, n_factors=<span class="number">40</span>, learning=<span class="string">'sgd'</span>, item_fact_reg=<span class="number">0.0</span>, user_fact_reg=<span class="number">0.0</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 item_bias_reg=<span class="number">0.0</span>, user_bias_reg=<span class="number">0.0</span>, verbose=False)</span>:</span></span><br><span class="line">        <span class="string">"""初始化</span></span><br><span class="line"><span class="string">        Params：</span></span><br><span class="line"><span class="string">        ratings : (ndarray) 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">        n_factors : (int) 矩阵分解模型中隐含特征的个数</span></span><br><span class="line"><span class="string">        learning ：(str) 优化的方法，als或sgd</span></span><br><span class="line"><span class="string">        item_fact_reg : (float) 物品隐变量正则化系数</span></span><br><span class="line"><span class="string">        user_fact_reg : (float) 用户隐变量正则化系数</span></span><br><span class="line"><span class="string">        item_bias_reg : (float) 物品偏差正则化系数</span></span><br><span class="line"><span class="string">        user_bias_reg ：(float) 用户偏差正则化系数</span></span><br><span class="line"><span class="string">        verbose : (bool) 是否输出训练进度信息</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.ratings = ratings</span><br><span class="line">        self.n_users, self.n_items = ratings.shape</span><br><span class="line">        self.n_factors = n_factors</span><br><span class="line">        self.learning = learning</span><br><span class="line">        self.item_fact_reg = item_fact_reg</span><br><span class="line">        self.user_fact_reg = user_fact_reg</span><br><span class="line">        self.item_bias_reg = item_bias_reg</span><br><span class="line">        self.user_bias_reg = user_bias_reg</span><br><span class="line">        <span class="keyword">if</span> self.learning == <span class="string">'sgd'</span>:</span><br><span class="line">            self.sample_row, self.sample_col = self.ratings.nonzero() <span class="comment">#获取评分矩阵中不为0的样本位置</span></span><br><span class="line">            self.n_samples = len(self.sample_row)</span><br><span class="line">        self._v = verbose</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als_step</span><span class="params">(self, latent_vectors, fixed_vecs, ratings, _lambda, type=<span class="string">'user'</span>)</span>:</span></span><br><span class="line">        <span class="string">"""ALS算法中的一步//type决定优化的是用户隐变量还是物品隐变量"""</span></span><br><span class="line">        <span class="keyword">if</span> type == <span class="string">'user'</span>:</span><br><span class="line">            YTY = fixed_vecs.T.dot(fixed_vecs)</span><br><span class="line">            lambdaI = np.eye(YTY.shape[<span class="number">0</span>]) * _lambda <span class="comment">#np.eye(n)返回一个n*n的单位对角矩阵</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> u <span class="keyword">in</span> range(latent_vectors.shape[<span class="number">0</span>]):</span><br><span class="line">                latent_vectors[u,:] = solve((YTY+lambdaI), ratings[u,:].dot(fixed_vecs)) <span class="comment">#解线性方程</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> type == <span class="string">'item'</span>:</span><br><span class="line">            XTX = fixed_vecs.T.dot(fixed_vecs)</span><br><span class="line">            lambdaI = np.eye(XTX.shape[<span class="number">0</span>]) * _lambda</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(ratings.shape[<span class="number">1</span>]):</span><br><span class="line">                latent_vectors[i,:] = solve((XTX+lambdaI), ratings[:, i].T.dot(fixed_vecs))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> latent_vectors</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""SGD算法更新变量"""</span></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> self.training_indices:</span><br><span class="line">            u = self.sample_row[idx]</span><br><span class="line">            i = self.sample_col[idx]</span><br><span class="line">            prediction = self.predict(u,i)</span><br><span class="line">            e = self.ratings[u,i] - prediction</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#更新变量</span></span><br><span class="line">            self.user_bias[u] += self.learning_rate * (e - self.user_bias_reg * self.user_bias[u])</span><br><span class="line">            self.item_bias[i] += self.learning_rate * (e - self.item_bias_reg * self.item_bias[i])</span><br><span class="line">            self.user_vects[u,:] += self.learning_rate * (e * self.item_vects[i,:] - self.user_fact_reg * self.user_vects[u,:])</span><br><span class="line">            self.item_vects[i,:] += self.learning_rate * (e * self.user_vects[u,:] - self.item_fact_reg * self.item_vects[i,:])</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial_train</span><span class="params">(self, n_iter)</span>:</span></span><br><span class="line">        <span class="string">"""部分训练，可多次调用"""</span></span><br><span class="line">        ctr = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> ctr &lt;= n_iter:</span><br><span class="line">            <span class="keyword">if</span> ctr%<span class="number">10</span> == <span class="number">0</span> <span class="keyword">and</span> self._v:</span><br><span class="line">                print(<span class="string">"current iteration &#123;&#125;\n"</span>.format(ctr))</span><br><span class="line">            <span class="keyword">if</span> self.learning == <span class="string">'als'</span>:</span><br><span class="line">                self.user_vects = self.als_step(self.user_vects, self.item_vects, self.ratings, self.user_reg, type=<span class="string">'user'</span>)</span><br><span class="line">                self.item_vects = self.als_step(self.item_vects, self.user_vects, self.ratings, self.item_reg, type=<span class="string">'item'</span>)</span><br><span class="line">            <span class="keyword">elif</span> self.learning == <span class="string">'sgd'</span>:</span><br><span class="line">                self.training_indices = np.arange(self.n_samples)</span><br><span class="line">                np.random.shuffle(self.training_indices)</span><br><span class="line">                self.sgd()</span><br><span class="line">            ctr += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, n_iter=<span class="number">10</span>, learning_rate=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="comment">#初始化用户和物品隐变量</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        迭代开始前，需要对user和item的特征向量赋初值，这个初值很重要，会严重地影响到计算速度。</span></span><br><span class="line"><span class="string">        一般的做法是在所有已评分的平均分附近产生一些随机数作为初值。</span></span><br><span class="line"><span class="string">        这里是以0为均值的正态分布，注意到sgd的global_bias赋值为已评分项目的平均分</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.user_vects = np.random.normal(scale=<span class="number">1.</span>/self.n_factors, size=(self.n_users, self.n_factors))</span><br><span class="line">        self.item_vects = np.random.normal(scale=<span class="number">1.</span>/self.n_factors, size=(self.n_items, self.n_factors))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.learning == <span class="string">'sgd'</span>:</span><br><span class="line">            self.learning_rate = learning_rate</span><br><span class="line">            self.user_bias = np.zeros(self.n_users)</span><br><span class="line">            self.item_bias = np.zeros(self.n_items)</span><br><span class="line">            self.global_bias = np.mean(self.ratings[np.where(self.ratings != <span class="number">0</span>)]) <span class="comment">#np.where(condition)返回为true的位置信息</span></span><br><span class="line">        </span><br><span class="line">        self.partial_train(n_iter)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, u, i)</span>:</span></span><br><span class="line">        <span class="string">"""预测用户u对物品i的评分"""</span></span><br><span class="line">        <span class="keyword">if</span> self.learning == <span class="string">'als'</span>:</span><br><span class="line">            <span class="keyword">return</span> self.user_vects[u,:].dot(self.item_vects[i,:].T)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.learning == <span class="string">'sgd'</span>:</span><br><span class="line">            prediction = self.global_bias + self.user_bias[u] + self.item_bias[i]</span><br><span class="line">            prediction += self.user_vects[u,:].dot(self.item_vects[i,:].T)</span><br><span class="line">            <span class="keyword">return</span> prediction</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""预测整个评分矩阵"""</span></span><br><span class="line">        predictions = np.zeros((self.user_vects.shape[<span class="number">0</span>], self.item_vects.shape[<span class="number">0</span>]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> u <span class="keyword">in</span> range(self.user_vects.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.item_vects.shape[<span class="number">0</span>]):</span><br><span class="line">                predictions[u,i] = self.predict(u,i)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_learning_curve</span><span class="params">(self, iter_array, test, learning_rate=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="string">"""在训练中实时追踪MSE值"""</span></span><br><span class="line">        iter_array.sort()</span><br><span class="line">        self.train_mse = []</span><br><span class="line">        self.test_mse = []</span><br><span class="line">        iter_diff = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> (i, n_iter) <span class="keyword">in</span> enumerate(iter_array):</span><br><span class="line">            <span class="keyword">if</span> self._v:</span><br><span class="line">                print(<span class="string">"Iteration: &#123;&#125;"</span>.format(n_iter))</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                self.train(n_iter - iter_diff, learning_rate)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.partial_train(n_iter - iter_diff)</span><br><span class="line">            </span><br><span class="line">            predictions = self.predict_all()</span><br><span class="line">            </span><br><span class="line">            self.train_mse += [get_mse(predictions, ratings)]</span><br><span class="line">            self.test_mse += [get_mse(predictions, test)]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> self._v:</span><br><span class="line">                print(<span class="string">"train mse: "</span>+ str(self.train_mse[<span class="number">-1</span>]))</span><br><span class="line">                print(<span class="string">"tset mse: "</span>+ str(self.test_mse[<span class="number">-1</span>]))</span><br><span class="line">            iter_diff = n_iter</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#尝试一下没有正则项的情况</span></span><br><span class="line">MF_SGD = ExplicitMF(train, <span class="number">40</span>, learning=<span class="string">'sgd'</span>, verbose=<span class="keyword">True</span>)</span><br><span class="line">iter_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>]</span><br><span class="line">MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Iteration: 1
train mse: 1.14628463997
tset mse: 1.18836560464
Iteration: 2
train mse: 1.07823224241
tset mse: 1.13840195287
Iteration: 5
train mse: 0.983642628014
tset mse: 1.06169986279
Iteration: 10
train mse: 0.926737377166
tset mse: 1.01119822302
Iteration: 25
current iteration 10

train mse: 0.875328541824
tset mse: 0.963611666894
Iteration: 50
current iteration 10

current iteration 20

train mse: 0.848022199506
tset mse: 0.942762793768
Iteration: 100
current iteration 10

current iteration 20

current iteration 30

current iteration 40

current iteration 50

train mse: 0.762576050753
tset mse: 0.919925489827
Iteration: 200
current iteration 10

current iteration 20

current iteration 30

current iteration 40

current iteration 50

current iteration 60

current iteration 70

current iteration 80

current iteration 90

current iteration 100

train mse: 0.450910156435
tset mse: 0.911759156192
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_learning_curve(iter_array, MF_SGD)</span><br></pre></td></tr></table></figure>
<p><img src="/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_13_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#尝试寻找最优的learning_rate #learning_rate的经验值在0.001的量级，取的太大会导致结果发散</span></span><br><span class="line">iter_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>]</span><br><span class="line">learning_rates = [<span class="number">1e-5</span>, <span class="number">1e-4</span>, <span class="number">1e-3</span>, <span class="number">1e-2</span>]</span><br><span class="line"></span><br><span class="line">best_params = &#123;&#125;</span><br><span class="line">best_params[<span class="string">'learning_rate'</span>] = <span class="keyword">None</span></span><br><span class="line">best_params[<span class="string">'n_iter'</span>] = <span class="number">0</span></span><br><span class="line">best_params[<span class="string">'train_mse'</span>] = np.inf</span><br><span class="line">best_params[<span class="string">'test_mse'</span>] = np.inf</span><br><span class="line">best_params[<span class="string">'model'</span>] = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> rate <span class="keyword">in</span> learning_rates:</span><br><span class="line">    print(<span class="string">'Rate: &#123;&#125;'</span>.format(rate))</span><br><span class="line">    MF_SGD = ExplicitMF(train, n_factors=<span class="number">40</span>, learning=<span class="string">'sgd'</span>)</span><br><span class="line">    MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=rate)</span><br><span class="line">    min_idx = np.argmin(MF_SGD.test_mse)</span><br><span class="line">    <span class="keyword">if</span> MF_SGD.test_mse[min_idx] &lt; best_params[<span class="string">'test_mse'</span>]:</span><br><span class="line">        best_params[<span class="string">'n_iter'</span>] = iter_array[min_idx]</span><br><span class="line">        best_params[<span class="string">'learning_rate'</span>] = rate</span><br><span class="line">        best_params[<span class="string">'train_mse'</span>] = MF_SGD.train_mse[min_idx]</span><br><span class="line">        best_params[<span class="string">'test_mse'</span>] = MF_SGD.test_mse[min_idx]</span><br><span class="line">        best_params[<span class="string">'model'</span>] = MF_SGD</span><br><span class="line">        print(<span class="string">'New optimal hyperparameters'</span>)</span><br><span class="line">        print(pd.Series(best_params))</span><br></pre></td></tr></table></figure>
<pre><code>Rate: 1e-05
New optimal hyperparameters
learning_rate                                             1e-05
model            &lt;__main__.ExplicitMF object at 0x7f4b65bc2f28&gt;
n_iter                                                      200
test_mse                                                1.13856
train_mse                                               1.07829
dtype: object
Rate: 0.0001
New optimal hyperparameters
learning_rate                                            0.0001
model            &lt;__main__.ExplicitMF object at 0x7f4b65bc2ef0&gt;
n_iter                                                      200
test_mse                                               0.973174
train_mse                                              0.885763
dtype: object
Rate: 0.001
New optimal hyperparameters
learning_rate                                             0.001
model            &lt;__main__.ExplicitMF object at 0x7f4b65bc2f28&gt;
n_iter                                                      200
test_mse                                               0.915707
train_mse                                              0.449158
dtype: object
Rate: 0.01
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#尝试寻找最优的隐变量维度和正则项系数</span></span><br><span class="line">iter_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>]</span><br><span class="line">latent_factors = [<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">80</span>, <span class="number">100</span>]  <span class="comment">#经验值在10-200之间</span></span><br><span class="line">regularizations = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.</span>]  <span class="comment">#经验值在0.01这个量级</span></span><br><span class="line">regularizations.sort()</span><br><span class="line"></span><br><span class="line">best_params = &#123;&#125;</span><br><span class="line">best_params[<span class="string">'n_factors'</span>] = latent_factors[<span class="number">0</span>]</span><br><span class="line">best_params[<span class="string">'reg'</span>] = regularizations[<span class="number">0</span>]</span><br><span class="line">best_params[<span class="string">'n_iter'</span>] = <span class="number">0</span></span><br><span class="line">best_params[<span class="string">'train_mse'</span>] = np.inf</span><br><span class="line">best_params[<span class="string">'test_mse'</span>] = np.inf</span><br><span class="line">best_params[<span class="string">'model'</span>] = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fact <span class="keyword">in</span> latent_factors:</span><br><span class="line">    print(<span class="string">'Factors: &#123;&#125;'</span>.format(fact))</span><br><span class="line">    <span class="keyword">for</span> reg <span class="keyword">in</span> regularizations:</span><br><span class="line">        print(<span class="string">'Regularization: &#123;&#125;'</span>.format(reg))</span><br><span class="line">        MF_SGD = ExplicitMF(train, n_factors=fact, learning=<span class="string">'sgd'</span>,\</span><br><span class="line">                            user_fact_reg=reg, item_fact_reg=reg, \</span><br><span class="line">                            user_bias_reg=reg, item_bias_reg=reg)</span><br><span class="line">        MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=<span class="number">0.001</span>)</span><br><span class="line">        min_idx = np.argmin(MF_SGD.test_mse)</span><br><span class="line">        <span class="keyword">if</span> MF_SGD.test_mse[min_idx] &lt; best_params[<span class="string">'test_mse'</span>]:</span><br><span class="line">            best_params[<span class="string">'n_factors'</span>] = fact</span><br><span class="line">            best_params[<span class="string">'reg'</span>] = reg</span><br><span class="line">            best_params[<span class="string">'n_iter'</span>] = iter_array[min_idx]</span><br><span class="line">            best_params[<span class="string">'train_mse'</span>] = MF_SGD.train_mse[min_idx]</span><br><span class="line">            best_params[<span class="string">'test_mse'</span>] = MF_SGD.test_mse[min_idx]</span><br><span class="line">            best_params[<span class="string">'model'</span>] = MF_SGD</span><br><span class="line">            print(<span class="string">'New optimal hyperparameters'</span>)</span><br><span class="line">            print(pd.Series(best_params))</span><br></pre></td></tr></table></figure>
<pre><code>Factors: 5
Regularization: 0.001
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bd1ac8&gt;
n_factors                                                 5
n_iter                                                  200
reg                                                   0.001
test_mse                                           0.943521
train_mse                                          0.690682
dtype: object
Regularization: 0.01
Regularization: 0.1
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bd1a90&gt;
n_factors                                                 5
n_iter                                                  200
reg                                                     0.1
test_mse                                             0.9214
train_mse                                          0.787169
dtype: object
Regularization: 1.0
Factors: 10
Regularization: 0.001
Regularization: 0.01
Regularization: 0.1
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bd1ac8&gt;
n_factors                                                10
n_iter                                                  200
reg                                                     0.1
test_mse                                           0.910786
train_mse                                          0.778982
dtype: object
Regularization: 1.0
Factors: 20
Regularization: 0.001
Regularization: 0.01
Regularization: 0.1
Regularization: 1.0
Factors: 40
Regularization: 0.001
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bd1a90&gt;
n_factors                                                40
n_iter                                                  200
reg                                                   0.001
test_mse                                           0.910651
train_mse                                          0.454182
dtype: object
Regularization: 0.01
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bc2ef0&gt;
n_factors                                                40
n_iter                                                  200
reg                                                    0.01
test_mse                                           0.897365
train_mse                                           0.49412
dtype: object
Regularization: 0.1
Regularization: 1.0
Factors: 80
Regularization: 0.001
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bd1a90&gt;
n_factors                                                80
n_iter                                                  200
reg                                                   0.001
test_mse                                           0.894096
train_mse                                          0.452232
dtype: object
Regularization: 0.01
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bc2ef0&gt;
n_factors                                                80
n_iter                                                  200
reg                                                    0.01
test_mse                                           0.886905
train_mse                                          0.512236
dtype: object
Regularization: 0.1
Regularization: 1.0
Factors: 100
Regularization: 0.001
Regularization: 0.01
New optimal hyperparameters
model        &lt;__main__.ExplicitMF object at 0x7f4b65bd1ac8&gt;
n_factors                                               100
n_iter                                                  200
reg                                                    0.01
test_mse                                           0.885906
train_mse                                          0.524852
dtype: object
Regularization: 0.1
Regularization: 1.0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#看看寻找到的最优参数值</span></span><br><span class="line">print(<span class="string">'Best regularization: &#123;&#125;'</span>.format(best_params[<span class="string">'reg'</span>]))</span><br><span class="line">print(<span class="string">'Best latent factors: &#123;&#125;'</span>.format(best_params[<span class="string">'n_factors'</span>]))</span><br><span class="line">print(<span class="string">'Best iterations: &#123;&#125;'</span>.format(best_params[<span class="string">'n_iter'</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>Best regularization: 0.01
Best latent factors: 100
Best iterations: 200
</code></pre><p><strong>这里的最好的隐变量个数和迭代次数都是我们设定的最大值，如果有更多时间，可以继续向更大的值尝试</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画出最优模型的训练曲线</span></span><br><span class="line">plot_learning_curve(iter_array, best_params[<span class="string">'model'</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/2018/03/29/Explicit-Matrix-Factorization-with-ALS-and-SGD/output_17_0.png" alt="png"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/REC/" rel="tag"># REC</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/23/Logistic-Regression/" rel="next" title="Logistic Regression">
                <i class="fa fa-chevron-left"></i> Logistic Regression
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/04/04/BPR论文阅读笔记/" rel="prev" title="BPR论文阅读笔记">
                BPR论文阅读笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
       
         <div onclick="ShowGitment()" id="gitment-display-button">显示 Gitment 评论</div>
         <div id="gitment-container" style="display:none"></div>
       
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/me.jpg"
               alt="lhy" />
          <p class="site-author-name" itemprop="name">lhy</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/chamlhy" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#一些假设"><span class="nav-number">1.</span> <span class="nav-text">一些假设</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数学公式"><span class="nav-number">2.</span> <span class="nav-text">数学公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最小化损失函数"><span class="nav-number">3.</span> <span class="nav-text">最小化损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ALS（交替最小二乘法）"><span class="nav-number">3.1.</span> <span class="nav-text">ALS（交替最小二乘法）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#求导"><span class="nav-number">3.1.1.</span> <span class="nav-text">求导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#实现"><span class="nav-number">3.1.2.</span> <span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SGD（随机梯度下降）"><span class="nav-number">3.2.</span> <span class="nav-text">SGD（随机梯度下降）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#新的评分-损失公式"><span class="nav-number">3.2.1.</span> <span class="nav-text">新的评分/损失公式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#变量更新规则"><span class="nav-number">3.2.2.</span> <span class="nav-text">变量更新规则</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#代码实现"><span class="nav-number">3.2.3.</span> <span class="nav-text">代码实现</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lhy</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






   
   
   
   
   <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
   <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
   
       <script type="text/javascript">
           function ShowGitment(){
               document.getElementById("gitment-display-button").style.display = "none";
               document.getElementById("gitment-container").style.display = "block";
               var gitment = new Gitment({
                   id: window.location.pathname, 
                   owner: 'chamlhy',
                   repo: 'lhy9comment',
                   oauth: {
                       client_id: '096b3c7f63f33ed0967b',
                       client_secret: '8c475778ba49e97751f8c7d0a982e9459b684010',
                   }});
               gitment.render('gitment-container');
           }
       </script>
   


  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
